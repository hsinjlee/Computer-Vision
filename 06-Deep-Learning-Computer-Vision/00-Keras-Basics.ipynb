{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Basics\n",
    "\n",
    "Welcome to the section on deep learning! We'll be using Keras with a TensorFlow backend to perform our deep learning operations.\n",
    "\n",
    "This means we should get familiar with some Keras fundamentals and basics!\n",
    "\n",
    "## Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will use the Bank Authentication Data Set to start off with. This data set consists of various image features derived from images that had 400 x 400 pixels. You should note **the data itself that we will be using ARE NOT ACTUAL IMAGES**, they are **features** of images. In the next lecture we will cover grabbing and working with image data with Keras. This notebook focuses on learning the basics of building a neural network with Keras.\n",
    "\n",
    "_____\n",
    "More info on the data set:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
    "\n",
    "Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. variance of Wavelet Transformed image (continuous) \n",
    "2. skewness of Wavelet Transformed image (continuous) \n",
    "3. curtosis of Wavelet Transformed image (continuous) \n",
    "4. entropy of image (continuous) \n",
    "5. class (integer) \n",
    "\n",
    "## Reading in the Data Set\n",
    "\n",
    "We've already downloaded the dataset, its in the DATA folder. So let's open it up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "data = genfromtxt('../DATA/bank_note_data.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699,   0.     ],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ,   0.     ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645,   0.     ],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ,   1.     ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ,   1.     ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ,   1.     ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Test\n",
    "\n",
    "Its time to split the data into a train/test set. Keep in mind, sometimes people like to split 3 ways, train/test/validation. We'll keep things simple for now. **Remember to check out the video explanation as to why we split and what all the parameters mean!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8734  , -0.033118, -0.20165 ,  0.55774 ],\n",
       "       [ 2.0177  ,  1.7982  , -2.9581  ,  0.2099  ],\n",
       "       [-0.36038 ,  4.1158  ,  3.1143  , -0.37199 ],\n",
       "       ...,\n",
       "       [-7.0364  ,  9.2931  ,  0.16594 , -4.5396  ],\n",
       "       [-3.4605  ,  2.6901  ,  0.16165 , -1.0224  ],\n",
       "       [-3.3582  , -7.2404  , 11.4419  , -0.57113 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5691  ,  6.3465  , -0.1828  , -2.4099  ],\n",
       "       [-0.27802 ,  8.1881  , -3.1338  , -2.5276  ],\n",
       "       [ 0.051979,  7.0521  , -2.0541  , -3.1508  ],\n",
       "       ...,\n",
       "       [ 3.5127  ,  2.9073  ,  1.0579  ,  0.40774 ],\n",
       "       [ 5.504   , 10.3671  , -4.413   , -4.0211  ],\n",
       "       [-0.2062  ,  9.2207  , -3.7044  , -6.8103  ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing the Data\n",
    "\n",
    "Usually when using Neural Networks, you will get better performance when you standardize the data. Standardization just means normalizing the values to all fit between a certain range, like 0-1, or -1 to 1.\n",
    "\n",
    "The scikit learn library also provides a nice function for this.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_object = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_object.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler_object.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler_object.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we have the data scaled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.9274"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8734  , -0.033118, -0.20165 ,  0.55774 ],\n",
       "       [ 2.0177  ,  1.7982  , -2.9581  ,  0.2099  ],\n",
       "       [-0.36038 ,  4.1158  ,  3.1143  , -0.37199 ],\n",
       "       ...,\n",
       "       [-7.0364  ,  9.2931  ,  0.16594 , -4.5396  ],\n",
       "       [-3.4605  ,  2.6901  ,  0.16165 , -1.0224  ],\n",
       "       [-3.3582  , -7.2404  , 11.4419  , -0.57113 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.44850688e-01, 5.14130449e-01, 2.18194638e-01, 8.50172258e-01],\n",
       "       [6.53339968e-01, 5.82655745e-01, 9.93242398e-02, 8.17696322e-01],\n",
       "       [4.81846700e-01, 6.69377018e-01, 3.61193167e-01, 7.63368407e-01],\n",
       "       ...,\n",
       "       [4.11050776e-04, 8.63104170e-01, 2.34046756e-01, 3.74261253e-01],\n",
       "       [2.58284115e-01, 6.16029366e-01, 2.33861752e-01, 7.02643151e-01],\n",
       "       [2.65661395e-01, 2.44444278e-01, 7.20316361e-01, 7.44775785e-01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network with Keras\n",
    "\n",
    "Let's build a simple neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model\n",
    "model = Sequential()\n",
    "# 8 Neurons, expects input of 4 features. \n",
    "# Play around with the number of neurons!!\n",
    "model.add(Dense(4, input_dim=4, activation='relu'))\n",
    "# Add another Densely Connected layer (every neuron connected to every neuron in the next layer)\n",
    "model.add(Dense(8, activation='relu'))\n",
    "# Last layer simple sigmoid function to output 0 or 1 (our label)\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit (Train) the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 1s - loss: 0.6860 - acc: 0.6899\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6736 - acc: 0.7312\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6523 - acc: 0.7552\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6259 - acc: 0.7813\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6026 - acc: 0.8052\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.5797 - acc: 0.8063\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.5564 - acc: 0.8063\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.5300 - acc: 0.8074\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.5021 - acc: 0.8139\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.4732 - acc: 0.8161\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.4477 - acc: 0.8303\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.4227 - acc: 0.8357\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.3989 - acc: 0.8651\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.3762 - acc: 0.8760\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.3561 - acc: 0.8857\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.3386 - acc: 0.8988\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.3215 - acc: 0.9075\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.3059 - acc: 0.9119\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.2923 - acc: 0.9119\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.2795 - acc: 0.9162\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.2681 - acc: 0.9173\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.2568 - acc: 0.9151\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.2462 - acc: 0.9206\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.2369 - acc: 0.9206\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.2275 - acc: 0.9238\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.2186 - acc: 0.9260\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.2109 - acc: 0.9304\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.2032 - acc: 0.9325\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.1955 - acc: 0.9347\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.1898 - acc: 0.9358\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.1827 - acc: 0.9369\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.1767 - acc: 0.9412\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.1698 - acc: 0.9445\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.1630 - acc: 0.9434\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.1585 - acc: 0.9489\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.1520 - acc: 0.9478\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.1467 - acc: 0.9521\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.1427 - acc: 0.9565\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.1374 - acc: 0.9576\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.1332 - acc: 0.9565\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.1286 - acc: 0.9587\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.1241 - acc: 0.9597\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.1202 - acc: 0.9608\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.1179 - acc: 0.9608\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.1133 - acc: 0.9630\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.1091 - acc: 0.9641\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.1056 - acc: 0.9695\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.1027 - acc: 0.9663\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0995 - acc: 0.9706\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0964 - acc: 0.9717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e7040efd68>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Play around with number of epochs as well!\n",
    "model.fit(scaled_X_train,y_train,epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting New Unseen Data\n",
    "\n",
    "Let's see how we did by predicting on **new data**. Remember, our model has **never** seen the test data that we scaled previously! This process is the exact same process you would use on totally brand new data. For example , a brand new bank note that you just analyzed ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62098955, 0.75284662, 0.21900753, 0.5730998 ],\n",
       "       [0.48778602, 0.82175665, 0.09174727, 0.56211079],\n",
       "       [0.51158363, 0.77924916, 0.13830875, 0.50392598],\n",
       "       ...,\n",
       "       [0.76115065, 0.62415668, 0.27251204, 0.83616757],\n",
       "       [0.9047516 , 0.90329171, 0.03658247, 0.42267079],\n",
       "       [0.49296526, 0.86039507, 0.06714046, 0.1622583 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02818654],\n",
       "       [0.6720486 ],\n",
       "       [0.31995395],\n",
       "       [0.02337857],\n",
       "       [0.13512793],\n",
       "       [0.00496608],\n",
       "       [0.10085369],\n",
       "       [0.01022704],\n",
       "       [0.01380725],\n",
       "       [0.03007368],\n",
       "       [0.7914054 ],\n",
       "       [0.9755942 ],\n",
       "       [0.0090083 ],\n",
       "       [0.8786496 ],\n",
       "       [0.3458806 ],\n",
       "       [0.49424657],\n",
       "       [0.96657133],\n",
       "       [0.9735864 ],\n",
       "       [0.99556386],\n",
       "       [0.84619445],\n",
       "       [0.06537452],\n",
       "       [0.0105136 ],\n",
       "       [0.9341441 ],\n",
       "       [0.06067463],\n",
       "       [0.99738914],\n",
       "       [0.0249918 ],\n",
       "       [0.00744933],\n",
       "       [0.9299182 ],\n",
       "       [0.0055119 ],\n",
       "       [0.00870965],\n",
       "       [0.7921429 ],\n",
       "       [0.0152553 ],\n",
       "       [0.03016261],\n",
       "       [0.9968637 ],\n",
       "       [0.990798  ],\n",
       "       [0.01596237],\n",
       "       [0.76246905],\n",
       "       [0.9517548 ],\n",
       "       [0.97447973],\n",
       "       [0.01286343],\n",
       "       [0.00302201],\n",
       "       [0.7868602 ],\n",
       "       [0.94697464],\n",
       "       [0.08442358],\n",
       "       [0.99678826],\n",
       "       [0.96989554],\n",
       "       [0.99083555],\n",
       "       [0.00395473],\n",
       "       [0.00194999],\n",
       "       [0.55249965],\n",
       "       [0.0058415 ],\n",
       "       [0.00952187],\n",
       "       [0.04420637],\n",
       "       [0.02252931],\n",
       "       [0.17314215],\n",
       "       [0.92833614],\n",
       "       [0.07820246],\n",
       "       [0.01293916],\n",
       "       [0.00303892],\n",
       "       [0.03648617],\n",
       "       [0.98948497],\n",
       "       [0.00890015],\n",
       "       [0.48490196],\n",
       "       [0.0064918 ],\n",
       "       [0.04428766],\n",
       "       [0.01446019],\n",
       "       [0.00868248],\n",
       "       [0.07089123],\n",
       "       [0.25720736],\n",
       "       [0.4699932 ],\n",
       "       [0.9395293 ],\n",
       "       [0.06261659],\n",
       "       [0.9167427 ],\n",
       "       [0.00704647],\n",
       "       [0.92924166],\n",
       "       [0.13248911],\n",
       "       [0.00642509],\n",
       "       [0.9752525 ],\n",
       "       [0.978683  ],\n",
       "       [0.8380417 ],\n",
       "       [0.6341743 ],\n",
       "       [0.07674978],\n",
       "       [0.5877001 ],\n",
       "       [0.01952397],\n",
       "       [0.0048554 ],\n",
       "       [0.01052759],\n",
       "       [0.04216524],\n",
       "       [0.99749017],\n",
       "       [0.32739767],\n",
       "       [0.04239821],\n",
       "       [0.05861694],\n",
       "       [0.00680602],\n",
       "       [0.8641879 ],\n",
       "       [0.95616525],\n",
       "       [0.01625564],\n",
       "       [0.99625957],\n",
       "       [0.99708563],\n",
       "       [0.26100352],\n",
       "       [0.06484366],\n",
       "       [0.05779878],\n",
       "       [0.99779934],\n",
       "       [0.00607919],\n",
       "       [0.09335276],\n",
       "       [0.04333934],\n",
       "       [0.9971168 ],\n",
       "       [0.00880378],\n",
       "       [0.02608551],\n",
       "       [0.53150356],\n",
       "       [0.9970198 ],\n",
       "       [0.9836475 ],\n",
       "       [0.95644826],\n",
       "       [0.9146836 ],\n",
       "       [0.00889349],\n",
       "       [0.99335563],\n",
       "       [0.8392954 ],\n",
       "       [0.98627555],\n",
       "       [0.00943721],\n",
       "       [0.9976084 ],\n",
       "       [0.996238  ],\n",
       "       [0.00888602],\n",
       "       [0.97474784],\n",
       "       [0.01421325],\n",
       "       [0.89397115],\n",
       "       [0.01265894],\n",
       "       [0.2788295 ],\n",
       "       [0.05728614],\n",
       "       [0.9613579 ],\n",
       "       [0.8291165 ],\n",
       "       [0.03191403],\n",
       "       [0.9589236 ],\n",
       "       [0.9945257 ],\n",
       "       [0.02488227],\n",
       "       [0.03656515],\n",
       "       [0.00733303],\n",
       "       [0.01145381],\n",
       "       [0.00706668],\n",
       "       [0.9172911 ],\n",
       "       [0.00907751],\n",
       "       [0.19769087],\n",
       "       [0.86474717],\n",
       "       [0.12955229],\n",
       "       [0.00445767],\n",
       "       [0.9701614 ],\n",
       "       [0.0012937 ],\n",
       "       [0.7473199 ],\n",
       "       [0.34129405],\n",
       "       [0.40921995],\n",
       "       [0.59199595],\n",
       "       [0.673047  ],\n",
       "       [0.06814773],\n",
       "       [0.6165713 ],\n",
       "       [0.9807268 ],\n",
       "       [0.99460477],\n",
       "       [0.00739284],\n",
       "       [0.9332681 ],\n",
       "       [0.00525483],\n",
       "       [0.947124  ],\n",
       "       [0.12936504],\n",
       "       [0.0516246 ],\n",
       "       [0.01379882],\n",
       "       [0.9970528 ],\n",
       "       [0.96339136],\n",
       "       [0.9929281 ],\n",
       "       [0.99592555],\n",
       "       [0.94389814],\n",
       "       [0.02821511],\n",
       "       [0.9511606 ],\n",
       "       [0.01082999],\n",
       "       [0.01184219],\n",
       "       [0.00344559],\n",
       "       [0.37052903],\n",
       "       [0.00623793],\n",
       "       [0.03564711],\n",
       "       [0.9936998 ],\n",
       "       [0.00266753],\n",
       "       [0.00360605],\n",
       "       [0.9823203 ],\n",
       "       [0.9973569 ],\n",
       "       [0.13434869],\n",
       "       [0.01696623],\n",
       "       [0.23827095],\n",
       "       [0.03642463],\n",
       "       [0.98103565],\n",
       "       [0.04083148],\n",
       "       [0.98460835],\n",
       "       [0.04052226],\n",
       "       [0.9773865 ],\n",
       "       [0.9682975 ],\n",
       "       [0.02560572],\n",
       "       [0.04930194],\n",
       "       [0.97703063],\n",
       "       [0.0237657 ],\n",
       "       [0.22368304],\n",
       "       [0.99515283],\n",
       "       [0.93413466],\n",
       "       [0.9841728 ],\n",
       "       [0.94134915],\n",
       "       [0.14312044],\n",
       "       [0.29989335],\n",
       "       [0.987151  ],\n",
       "       [0.9989796 ],\n",
       "       [0.9864173 ],\n",
       "       [0.01219536],\n",
       "       [0.03424763],\n",
       "       [0.9903198 ],\n",
       "       [0.99455875],\n",
       "       [0.99281573],\n",
       "       [0.69703394],\n",
       "       [0.06310466],\n",
       "       [0.01533173],\n",
       "       [0.30901846],\n",
       "       [0.02112484],\n",
       "       [0.02998001],\n",
       "       [0.07769966],\n",
       "       [0.01495428],\n",
       "       [0.02478889],\n",
       "       [0.13248911],\n",
       "       [0.02161258],\n",
       "       [0.99462044],\n",
       "       [0.98254436],\n",
       "       [0.96272314],\n",
       "       [0.97259843],\n",
       "       [0.9721132 ],\n",
       "       [0.00231086],\n",
       "       [0.93136024],\n",
       "       [0.00306753],\n",
       "       [0.0821906 ],\n",
       "       [0.9982889 ],\n",
       "       [0.99601114],\n",
       "       [0.97768605],\n",
       "       [0.9557759 ],\n",
       "       [0.01664674],\n",
       "       [0.87246674],\n",
       "       [0.01223086],\n",
       "       [0.9503618 ],\n",
       "       [0.9971464 ],\n",
       "       [0.95912236],\n",
       "       [0.9865802 ],\n",
       "       [0.0600194 ],\n",
       "       [0.00478761],\n",
       "       [0.22961897],\n",
       "       [0.9319203 ],\n",
       "       [0.00541192],\n",
       "       [0.98957366],\n",
       "       [0.9662111 ],\n",
       "       [0.97455704],\n",
       "       [0.0295522 ],\n",
       "       [0.11193582],\n",
       "       [0.02311656],\n",
       "       [0.00228623],\n",
       "       [0.00615092],\n",
       "       [0.01895308],\n",
       "       [0.9819511 ],\n",
       "       [0.4903107 ],\n",
       "       [0.2757226 ],\n",
       "       [0.00727296],\n",
       "       [0.02595072],\n",
       "       [0.00254659],\n",
       "       [0.9857011 ],\n",
       "       [0.9772703 ],\n",
       "       [0.00172962],\n",
       "       [0.193363  ],\n",
       "       [0.01035654],\n",
       "       [0.98173106],\n",
       "       [0.89945644],\n",
       "       [0.03555209],\n",
       "       [0.9658006 ],\n",
       "       [0.02922799],\n",
       "       [0.99673456],\n",
       "       [0.9042856 ],\n",
       "       [0.98507404],\n",
       "       [0.92119986],\n",
       "       [0.00523805],\n",
       "       [0.6720435 ],\n",
       "       [0.02621076],\n",
       "       [0.02401001],\n",
       "       [0.04638264],\n",
       "       [0.9963677 ],\n",
       "       [0.00995469],\n",
       "       [0.04855104],\n",
       "       [0.9896595 ],\n",
       "       [0.00981246],\n",
       "       [0.9885775 ],\n",
       "       [0.01082522],\n",
       "       [0.02134596],\n",
       "       [0.9862937 ],\n",
       "       [0.02226186],\n",
       "       [0.00483004],\n",
       "       [0.00516959],\n",
       "       [0.10822067],\n",
       "       [0.0084602 ],\n",
       "       [0.997787  ],\n",
       "       [0.9964276 ],\n",
       "       [0.00186886],\n",
       "       [0.99642986],\n",
       "       [0.0348974 ],\n",
       "       [0.9211743 ],\n",
       "       [0.9980064 ],\n",
       "       [0.00853597],\n",
       "       [0.30901015],\n",
       "       [0.0915263 ],\n",
       "       [0.02136118],\n",
       "       [0.00219713],\n",
       "       [0.09924366],\n",
       "       [0.01199025],\n",
       "       [0.99114555],\n",
       "       [0.99594694],\n",
       "       [0.98337686],\n",
       "       [0.07435505],\n",
       "       [0.00719671],\n",
       "       [0.85539156],\n",
       "       [0.951479  ],\n",
       "       [0.00589839],\n",
       "       [0.29123047],\n",
       "       [0.01914214],\n",
       "       [0.00971328],\n",
       "       [0.00583483],\n",
       "       [0.00463287],\n",
       "       [0.9914409 ],\n",
       "       [0.08576509],\n",
       "       [0.97888035],\n",
       "       [0.8169885 ],\n",
       "       [0.981783  ],\n",
       "       [0.01352465],\n",
       "       [0.00468381],\n",
       "       [0.0052224 ],\n",
       "       [0.00604367],\n",
       "       [0.91257685],\n",
       "       [0.29309326],\n",
       "       [0.00851046],\n",
       "       [0.02025823],\n",
       "       [0.01267102],\n",
       "       [0.01577125],\n",
       "       [0.00357722],\n",
       "       [0.0150634 ],\n",
       "       [0.9894783 ],\n",
       "       [0.01013863],\n",
       "       [0.99037045],\n",
       "       [0.99902296],\n",
       "       [0.87579113],\n",
       "       [0.9423279 ],\n",
       "       [0.02228113],\n",
       "       [0.9165664 ],\n",
       "       [0.9894079 ],\n",
       "       [0.00107114],\n",
       "       [0.9542574 ],\n",
       "       [0.8924055 ],\n",
       "       [0.00377721],\n",
       "       [0.05106717],\n",
       "       [0.712343  ],\n",
       "       [0.03630201],\n",
       "       [0.00291087],\n",
       "       [0.90423995],\n",
       "       [0.00414221],\n",
       "       [0.9301244 ],\n",
       "       [0.02290311],\n",
       "       [0.8644645 ],\n",
       "       [0.95393676],\n",
       "       [0.01019909],\n",
       "       [0.01840731],\n",
       "       [0.9756645 ],\n",
       "       [0.00426498],\n",
       "       [0.06281322],\n",
       "       [0.08942431],\n",
       "       [0.0078424 ],\n",
       "       [0.01121516],\n",
       "       [0.01088886],\n",
       "       [0.99279404],\n",
       "       [0.06274103],\n",
       "       [0.02141161],\n",
       "       [0.9955309 ],\n",
       "       [0.08727538],\n",
       "       [0.03499807],\n",
       "       [0.03605246],\n",
       "       [0.05458324],\n",
       "       [0.9781385 ],\n",
       "       [0.9894097 ],\n",
       "       [0.00437034],\n",
       "       [0.9748984 ],\n",
       "       [0.00585689],\n",
       "       [0.9938698 ],\n",
       "       [0.9093756 ],\n",
       "       [0.9389556 ],\n",
       "       [0.00649345],\n",
       "       [0.87329745],\n",
       "       [0.38858074],\n",
       "       [0.00267367],\n",
       "       [0.98941666],\n",
       "       [0.97051585],\n",
       "       [0.00188864],\n",
       "       [0.98906076],\n",
       "       [0.01875248],\n",
       "       [0.01555447],\n",
       "       [0.00270572],\n",
       "       [0.9903605 ],\n",
       "       [0.9798922 ],\n",
       "       [0.63463676],\n",
       "       [0.0087404 ],\n",
       "       [0.15131144],\n",
       "       [0.01119004],\n",
       "       [0.01172933],\n",
       "       [0.98350763],\n",
       "       [0.03636817],\n",
       "       [0.00691215],\n",
       "       [0.96828777],\n",
       "       [0.99663347],\n",
       "       [0.8904313 ],\n",
       "       [0.98230076],\n",
       "       [0.0031988 ],\n",
       "       [0.9674887 ],\n",
       "       [0.01117961],\n",
       "       [0.06194049],\n",
       "       [0.91635644],\n",
       "       [0.5919986 ],\n",
       "       [0.1496871 ],\n",
       "       [0.9990489 ],\n",
       "       [0.03655932],\n",
       "       [0.9455765 ],\n",
       "       [0.02935837],\n",
       "       [0.0222914 ],\n",
       "       [0.00457699],\n",
       "       [0.9859556 ],\n",
       "       [0.87958956],\n",
       "       [0.01188534],\n",
       "       [0.00296124],\n",
       "       [0.00181431],\n",
       "       [0.9924799 ],\n",
       "       [0.01501255],\n",
       "       [0.0142458 ],\n",
       "       [0.9771986 ],\n",
       "       [0.01071477],\n",
       "       [0.01487357],\n",
       "       [0.00754328],\n",
       "       [0.01323464],\n",
       "       [0.7560246 ],\n",
       "       [0.01405544],\n",
       "       [0.98625946],\n",
       "       [0.00464236],\n",
       "       [0.30901015],\n",
       "       [0.95722294],\n",
       "       [0.0214222 ],\n",
       "       [0.02548311],\n",
       "       [0.02013159],\n",
       "       [0.00520943],\n",
       "       [0.00549548],\n",
       "       [0.02508592],\n",
       "       [0.9699921 ],\n",
       "       [0.9626882 ],\n",
       "       [0.004757  ],\n",
       "       [0.00542526],\n",
       "       [0.00795193],\n",
       "       [0.0054469 ],\n",
       "       [0.23827095]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spits out probabilities by default.\n",
    "model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model Performance\n",
    "\n",
    "So how well did we do? How do we actually measure \"well\". Is 95% accuracy good enough? It all depends on the situation. Also we need to take into account things like recall and precision. Make sure to watch the video discussion on classification evaluation before running this code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 135us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08766084403687754, 0.9735099337748344]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=scaled_X_test,y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[254,   3],\n",
       "       [  9, 187]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.99      0.98       257\n",
      "        1.0       0.98      0.95      0.97       196\n",
      "\n",
      "avg / total       0.97      0.97      0.97       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Models\n",
    "\n",
    "Now that we have a model trained, let's see how we can save and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myfirstmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = load_model('myfirstmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You now know how to preprocess data, train a neural network, and evaluate its classification performance!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-cvcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
